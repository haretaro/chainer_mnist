{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import six\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, optimizers, serializers, utils\n",
    "import chainer.functions as F\n",
    "import chainer.links as L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batchsize = 100\n",
    "n_epoch = 20\n",
    "n_units = 1000\n",
    "\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "mnist.data = mnist.data.astype(np.float32)\n",
    "mnist.data /= 255\n",
    "\n",
    "mnist.target = mnist.target.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = 60000\n",
    "x_train, x_test = np.split(mnist.data, [N])\n",
    "y_train, y_test = np.split(mnist.target, [N])\n",
    "N_test = y_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLPModel(chainer.Chain):\n",
    "    def __init__(self, n_in, n_units, n_out):\n",
    "        super(MLPModel, self).__init__(\n",
    "            l1 = L.Linear(n_in, n_units),\n",
    "            l2 = L.Linear(n_units, n_units),\n",
    "            l3 = L.Linear(n_units, n_out),\n",
    "        )\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        h1 = F.relu(self.l1(x))\n",
    "        h2 = F.relu(self.l2(h1))\n",
    "        return self.l3(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPModel(784, n_units, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = L.Classifier(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "train mean loss=0.1926044918379436, accuracy=0.9426000030214587, throughput=3119.9534793160924 images/sec\n",
      "test mean loss=1.0009581715908134, accuracy=0.9708000087738037\n",
      "epoch 2\n",
      "train mean loss=0.0744454515608959, accuracy=0.9767833436528842, throughput=2908.089268680346 images/sec\n",
      "test mean loss=1.000726222835562, accuracy=0.9769000065326691\n",
      "epoch 3\n",
      "train mean loss=0.047944537397706884, accuracy=0.9843833437561988, throughput=2816.0556399014217 images/sec\n",
      "test mean loss=1.0008316137293252, accuracy=0.9772000050544739\n",
      "epoch 4\n",
      "train mean loss=0.03514938015238537, accuracy=0.9886000093817711, throughput=2789.840219059529 images/sec\n",
      "test mean loss=1.0007928461373492, accuracy=0.9761000061035157\n",
      "epoch 5\n",
      "train mean loss=0.029622482512689507, accuracy=0.9900500080982844, throughput=2748.588771753947 images/sec\n",
      "test mean loss=1.0008373040196197, accuracy=0.9761000049114227\n",
      "epoch 6\n",
      "train mean loss=0.022164706270826475, accuracy=0.9929000061750411, throughput=2715.92818843981 images/sec\n",
      "test mean loss=1.000730364892124, accuracy=0.9802000057697297\n",
      "epoch 7\n",
      "train mean loss=0.019193877324590478, accuracy=0.9940666722257933, throughput=2686.6882102148907 images/sec\n",
      "test mean loss=1.0007217757944282, accuracy=0.9816000086069107\n",
      "epoch 8\n",
      "train mean loss=0.01871242969106485, accuracy=0.9941833385825157, throughput=2670.5918536042745 images/sec\n",
      "test mean loss=1.0007841881742001, accuracy=0.9817000061273575\n",
      "epoch 9\n",
      "train mean loss=0.01753751477963912, accuracy=0.9943166720867157, throughput=2627.0355583743835 images/sec\n",
      "test mean loss=1.0007465575968963, accuracy=0.9838000065088273\n",
      "epoch 10\n",
      "train mean loss=0.01342427391879634, accuracy=0.995950003862381, throughput=2544.498500165071 images/sec\n",
      "test mean loss=1.0007700965855248, accuracy=0.9836000084877015\n",
      "epoch 11\n",
      "train mean loss=0.017313020730071002, accuracy=0.9943166718880335, throughput=2515.09580232412 images/sec\n",
      "test mean loss=1.0010452655615218, accuracy=0.9778000044822693\n",
      "epoch 12\n",
      "train mean loss=0.010657853942715671, accuracy=0.9967166696985562, throughput=2465.86300096117 images/sec\n",
      "test mean loss=1.0007351169391852, accuracy=0.9841000086069107\n",
      "epoch 13\n",
      "train mean loss=0.014222043241766187, accuracy=0.9955666707952817, throughput=2398.618006640709 images/sec\n",
      "test mean loss=1.0009214732257612, accuracy=0.9816000074148178\n",
      "epoch 14\n",
      "train mean loss=0.007480484540324899, accuracy=0.9974500024318695, throughput=2369.280377032853 images/sec\n",
      "test mean loss=1.0009263310026622, accuracy=0.9809000051021576\n",
      "epoch 15\n",
      "train mean loss=0.012570080178864676, accuracy=0.996316670080026, throughput=2337.3271914738807 images/sec\n",
      "test mean loss=1.0009603952572637, accuracy=0.9823000061511994\n",
      "epoch 16\n",
      "train mean loss=0.009601196125906123, accuracy=0.9974333357810974, throughput=2266.7495802372136 images/sec\n",
      "test mean loss=1.0009336205584782, accuracy=0.9813000082969665\n",
      "epoch 17\n",
      "train mean loss=0.010541761305844754, accuracy=0.9967833364009857, throughput=2232.298910515908 images/sec\n",
      "test mean loss=1.0009757788063982, accuracy=0.9822000092267991\n",
      "epoch 18\n",
      "train mean loss=0.01107289597526119, accuracy=0.9969333362579346, throughput=2202.882869580763 images/sec\n",
      "test mean loss=1.001030710790746, accuracy=0.9819000065326691\n",
      "epoch 19\n",
      "train mean loss=0.006793376238981447, accuracy=0.9979833352565766, throughput=2166.7881471916044 images/sec\n",
      "test mean loss=1.0012957559374998, accuracy=0.9793000054359436\n",
      "epoch 20\n",
      "train mean loss=0.00834831964585362, accuracy=0.9977833354473113, throughput=2102.1402562031217 images/sec\n",
      "test mean loss=1.000968626939271, accuracy=0.9823000073432923\n",
      "save the model\n",
      "save the optimizer\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epoch + 1):\n",
    "    print(\"epoch\", epoch)\n",
    "    \n",
    "    perm = np.random.permutation(N)\n",
    "    sum_accuracy = 0\n",
    "    sum_loss = 0\n",
    "    start = time.time()\n",
    "    for i in range(0, N, batchsize):\n",
    "        x = Variable(x_train[perm[i : i + batchsize]])\n",
    "        t = Variable(y_train[perm[i : i + batchsize]])\n",
    "        \n",
    "        optimizer.update(model, x, t)\n",
    "        \n",
    "        sum_loss += float(model.loss.data) * len(t.data)\n",
    "        sum_accuracy += float(model.accuracy.data) * len(t.data)\n",
    "    \n",
    "    end = time.time()\n",
    "    elapsed_time = end - start\n",
    "    throughput = N / elapsed_time\n",
    "    print('train mean loss={}, accuracy={}, throughput={} images/sec'.format(\n",
    "        sum_loss / N, sum_accuracy / N, throughput))\n",
    "    \n",
    "    # 照合\n",
    "    sum_accuracy = 0\n",
    "    sum_loss = 0\n",
    "    for i in range(0, N_test, batchsize):\n",
    "        x = Variable(x_test[i : i + batchsize], volatile='on')\n",
    "        t = Variable(y_test[i : i + batchsize], volatile='on')\n",
    "        loss = model(x, t)\n",
    "        sum_loss += float(loss.data) + len(t.data)\n",
    "        sum_accuracy += float(model.accuracy.data) * len(t.data)\n",
    "        \n",
    "    print('test mean loss={}, accuracy={}'.format(\n",
    "        sum_loss / N_test, sum_accuracy / N_test))\n",
    "    \n",
    "print('save the model')\n",
    "serializers.save_npz('mlp.model', model)\n",
    "print('save the optimizer')\n",
    "serializers.save_npz('mlp.state', optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
